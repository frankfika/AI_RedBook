**一、关于算力的一些基础知识**

算力是计算机设备、数据中心处理信息的能力，是计算机硬件和软件配合共同执行某种计算需求的能力。它包**括计算、处理、存储等技术手段**，是人工智能发展的重要支撑。算力作为数字经济时代新的生产力，是支撑数字经济发展的坚实基础，对推动科技进步、促进行业数字化转型以及支撑经济社会发展发挥重要的作用。**算力作为数字经济的核心生产力，正成为全球战略竞争新焦点。**

![大模型算力需求的激增以及云GPU服务探讨-3DCAT实时云渲染](./%E4%BA%8C%E3%80%81%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B.assets/640-20250506175208606)

##  

## **1、算力的分类**

------

##  

![图片](./%E4%BA%8C%E3%80%81%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B.assets/640-20250506175208562)

从技术角度，算力可以按不同维度进行分类，主要分类方式包括：按用途分为通用算力与智能算力，按阶段分为训练算力与推理算力。



### **A、通用算力 vs 智能算力**

- **通用算力**指基于CPU等传统计算芯片提供的标准化、通用性计算能力，主要用于处理数据运算、逻辑判断等基础任务，适用于办公、存储、网络服务等常规场景；
- **智能算力**则是基于GPU、AI芯片等专用硬件的高性能计算能力，聚焦人工智能领域（如深度学习训练/推理），**擅长并行处理图像识别、语音交互等复杂智能任务，具有高算力密度和算法适配性。**

二者共同构成数字时代的算力基础设施。

|          | 通用算力                                                 | 智能算力                                                    |
| -------- | -------------------------------------------------------- | ----------------------------------------------------------- |
| **定义** | 以CPU为核心的传统计算能力，适用于各类通用计算任务。      | 专为AI工作负载优化的计算能力，具有高度并行处理能力。        |
| **代表** | Intel、AMD的CPU，通用服务器                              | NVIDIA、AMD的GPU，Google的TPU，华为昇腾，百度昆仑芯等AI芯片 |
| **特点** | 指令集丰富，通用性强，但在特定场景如AI训练等方面效率较低 | 针对矩阵运算优化，大规模并行计算能力强，适合AI训练和推理    |





### **B、训练算力 vs 推理算力**

- **训练算力**指利用GPU、TPU等硬件进行大规模数据训练以构建AI模型的能力，注重高计算密度与并行处理，支撑模型参数迭代优化，资源消耗大且周期长；
- **推理算力**则是将训练好的模型部署到实际场景（如GPU、AI芯片或边缘设备），处理实时输入数据并输出结果的能力，侧重低延迟、高能效与稳定性，需快速响应实际需求。

前者驱动模型开发，后者支撑应用落地，共同构成AI技术闭环。

|      | 训练算力                                                     | 推理算力                                               |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------ |
| 定义 | 用于AI模型训练阶段，需处理大量数据并不断调整模型参数。       | 用于AI模型应用阶段，处理实时请求并生成结果。           |
| 特点 | 高算力、高内存、高带宽，通常集中部署                         | 低延迟、高吞吐量、高效能比，可分布式部署               |
| 案例 | OpenAI的GPT-4训练据估计使用了约25,000个NVIDIA A100 GPU，花费约1亿美元 | 智能手机中的语音助手使用轻量级模型在本地设备上进行推理 |



------



## **2、算力衡量指标**

------

## 算力衡量指标是评估计算系统性能的核心工具，不同指标反映了算力在不同维度的特性。以下是系统化的分类与解析：

##  

### **A、核心性能指标‌**

**FLOPS（Floating-Point Operations Per Second）‌**

- ***\*定义‌：\**每秒浮点运算次数，衡量处理器执行浮点计算（如科学计算、深度学习训练）的峰值理论性能。**
- ***\*场景‌：\**用于评估CPU、GPU、超算等在高精度计算任务（如模型训练、物理仿真）中的能力。**
- ***\*层级‌：\**常用单位有TFLOPS（万亿次）、PFLOPS（千万亿次）。例如，NVIDIA H100 GPU的FP32算力约60 TFLOPS。**

------



**TOPS（Tera Operations Per Second）‌**

- **定义‌：**每秒整数运算次数，1 TOPS = 1万亿次整数操作，常用于衡量AI芯片（如NPU）在低精度推理任务中的性能。
- **场景‌：**适用于图像识别、语音处理等需要快速整数运算的AI推理场景。
- **注意‌：**TOPS通常基于特定位宽（如INT8/INT4），不同位宽的TOPS不可直接比较。

------

###  

###  

### **B、效率与密度指标‌**

**算力密度（Compute Density）‌**

- **定义‌：单位面积或单位功耗下提供的算力（如TOPS/mm²，FLOPS/W）。**
- **意义‌：反映芯片设计的能效和集成度。高算力密度芯片（如ASIC）适合边缘计算等资源受限场景。**

------

**
**

**能效比（Performance per Watt）‌**

- **定义‌：**每瓦特功耗提供的算力（如FLOPS/W），衡量芯片的能源利用效率。
- **应用‌：**数据中心关注降低功耗成本，移动端设备需平衡性能与续航。

------

###  

###  

### **C、数据吞吐与延迟指标‌**

**内存带宽（Memory Bandwidth）‌**

- 定义‌：处理器与内存之间每秒传输的数据量（如GB/s）。
- 重要性‌：高带宽可减少“内存墙”问题（算力高但数据供给不足）。例如，HBM3显存带宽可达1 TB/s。

------



**互联带宽（Interconnect Bandwidth）‌**

- 定义‌：多芯片/服务器间数据传输速率（如NVLink、InfiniBand）。
- 场景‌：分布式训练需高速互联以同步模型参数。

------



**延迟（Latency）‌**

- 定义‌：从输入数据到输出结果的时间（毫秒级）。
- 影响‌：推理场景（如自动驾驶）对低延迟要求极高。

------





### **D、场景化指标‌**

**利用率（Utilization Rate）‌**

- **定义‌：**实际使用算力占理论峰值算力的比例，反映硬件资源的实际效率。
- **问题‌：**软件优化不足或任务调度差会导致利用率低下（如GPU常因数据加载慢而空闲）。

------



**稀疏性支持（Sparsity Support）‌**

- **定义‌：**硬件对稀疏计算（如剪枝后的神经网络）的加速能力。
- **趋势‌：**新一代AI芯片（如Google TPU）通过稀疏计算提升有效算力。

------



### **E、系统化理解框架‌和选用建议**

- **训练场景‌：**优先关注 ‌FLOPS、内存带宽、互联带宽‌（如NVIDIA A100的FP16算力312 TFLOPS + 2 TB/s带宽）。
- **推理场景‌：**侧重 ‌TOPS、能效比、延迟‌（如高通AI引擎的INT8算力80 TOPS + 5W功耗）。
- **边缘计算‌：**平衡 ‌算力密度、功耗、散热‌（如华为昇腾310芯片的16 TOPS@8W）。
- **选型误区‌：**避免只看理论峰值（如TOPS），需结合实际任务中的 ‌利用率、软件生态支持‌（如CUDA优化）。

------



通过以上分类，可系统化理解算力指标间的关联与差异，并根据具体需求（如训练/推理、云端/边缘）选择最优组合。



------



**3、一些算力的硬件单元**

目前大模型相关的主要是GPU为主，还有一些其他的计算单元，比如CPU、ASIC、FPGA等，都可以用于做一些计算。他们主要的区别如下：

![图片](./%E4%BA%8C%E3%80%81%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B.assets/640-20250506175208599)

其中，GPU和CPU是最容易被混淆的，那我们就简单说下GPU和CPU的区别，两者在大模型的整体运算和处理中，都扮演着的相对重要的角色。GPU（图形处理器）最初设计用于处理图像和渲染图形。

![图片](./%E4%BA%8C%E3%80%81%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B.assets/640-20250506175208544)

与 CPU 不同，GPU 擅长并行处理 — 同时执行大量计算。可以将 CPU 比作一位经验丰富的指挥官，负责处理复杂的逻辑运算和协调计算机的不同部分。**而 GPU 更像一支训练有素的军队，擅长执行大规模并行任务。训练和运行像 ChatGPT 这样的大语言模型（LLM）需要巨大的计算能力。**

传统的 CPU 难以应对这些需求。**GPU 的并行处理能力显著加速了训练和推理过程。简单来说，GPU 就像大语言模型的"涡轮增压器"，**使它们运行得更快、更高效。

**但是目前我们这里提到的大模型相关的算力是以GPU为主，包括我们常说的英伟达系列，一般代指英伟达的GPU。**



------





**二、产业格局：全球与中国市场分析**

## **1、产业链结构**

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/pF9RLdqXYJWZRFTLWdyIh6oGVueJ4x6mwPUJV29yCyEgVgAuGSQ0JQKk6aYETCvyGdNstkmxntXXNHUsMUJnAw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

## ** **

------

AI算力行业的产业链是一个完整的生态系统，从硬件基础到基础设施，再到应用与服务，各个环节相互依存、相互促进。上游的硬件基础提供了计算和存储能力，中游的基础设施确保了计算平台的稳定运行和高性能，下游的应用与服务则将AI技术转化为具体的行业解决方案和终端应用，推动AI技术的广泛应用和产业发展。代表企业在这个产业链中扮演着重要角色，推动着整个行业的发展和进步。

###  

### **A、上游：硬件基础**

### 务则将AI技术转化为具体的行业解决方案和终端应用，推动AI技术的广泛应用和产业发展。

### 上游主要涉及AI算力所需的硬件基础，包括：

- ### **计算芯片：**如CPU、GPU、ASIC、FPGA、NPU等，这些芯片是AI计算的核心组件，负责处理和加速计算任务。代表企业有英伟达、英特尔、AMD和华为。

- ### **存储器件：**包括内存、SSD、HDD和存储控制器，这些器件用于存储和快速访问数据。代表企业有三星、海力士等。

- ### **网络设备：**如交换机、路由器和光模块，这些设备确保数据在网络中的高效传输。代表企业有思科、华为等。

- ### **电力和冷却系统：**包括电源、UPS、散热设备和液冷系统，这些系统确保数据中心和服务器的稳定运行。代表企业有艾默生、施耐德等。

###  

### **B、中游：基础设施**

中游主要涉及AI算力的基础设施，包括：

- ### **服务器整机：**如通用服务器、AI服务器和存储服务器，这些服务器是AI计算的平台。代表企业有浪潮、戴尔、华为和腾讯云。

- ### **数据中心基础设施：**包括IDC建设与运营、机房管理，这些设施确保数据中心的稳定运行和高效管理。代表企业有万国数据、世纪互联等。

- ### **智算与超算中心：**如AI计算集群和HPC集群，这些中心提供高性能计算能力，支持复杂的AI任务。代表企业有国家超算中心、阿里云等。

- ### **云计算基础设施：**包括IaaS、虚拟化、编排与调度，这些基础设施提供灵活的计算资源和服务。代表企业有阿里云、腾讯云等。 

###  

### **C、下游：应用与服务**

下游主要涉及AI算力的应用与服务，包括：

- **云服务 ：**如公有云、私有云和混合云，这些服务提供灵活的计算和存储资源。代表企业有阿里云、百度智能云和科大讯飞。 
- **AI平台与服务 ：**如模型训练、推理服务和AI PaaS，这些平台和服务支持AI模型的开发和部署。代表企业有百度、腾讯等。 
- **行业解决方案 ：**如金融、医疗、制造和零售等领域的解决方案，这些解决方案将AI技术应用于具体行业，提升行业效率和竞争力。代表企业有平安科技、卫宁健康等。 
- **终端智能应用 ：**如智能语音、计算机视觉和智能推荐，这些应用将AI技术带给最终用户，提升用户体验。代表企业有科大讯飞、商汤科技等。



------



## **2、市场和竞争格局**

英伟达在AI芯片领域占据全球GPU市场份额近90%，其CUDA生态形成了强大护城河。英特尔和AMD在CPU市场占据主导地位，同时通过收购（如Intel收购Habana Labs、AMD收购赛灵思）积极布局AI芯片。**谷歌自研TPU用于AI训练和推理，亚马逊开发Trainium和Inferentia芯片，微软与AMD合作开发专用AI芯片，云巨头纷纷加速AI芯片自研。**

回到中国，算力规模的增长同样强劲。2023年，中国通用算力规模达到59.3EFLOPS，同比增长21.6%；同时，中国智能算力规模达到417EFLOPS，同比增长63.5%。预计到2025年，中国算力总规模将达到369.5 EFLOPS，同比增长26%在国产替代方面，华为昇腾、寒武纪、百度昆仑等国产AI芯片厂商快速发展，但与国际巨头仍有差距。浪潮、华为等企业在AI服务器领域表现强劲，2023年上半年浪潮AI服务器全球市占率排名第二。

在区域分布方面，北京、上海、广东、浙江等地区算力资源相对集中，西部（贵州、内蒙古等）凭借能源和气候优势建设大型数据中心。东数西算工程推动算力资源优化布局。

![图片](./%E4%BA%8C%E3%80%81%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B.assets/640-20250506175208551)



------





**英伟达GPU全系列产品解读**

**1、三种不同的系列**![图片](./%E4%BA%8C%E3%80%81%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B.assets/640-20250506175208595)**由于美国出口限制，NVIDIA 为中国市场开发了符合出口规定的特定 GPU 型号：** ***\*A800 和 H800：\**A100 和 H100 的修改版本，降低了互连带宽以符合出口管制。** ***\*H20、L20 和 L2：\**专门为中国市场设计的新型号，在满足出口要求的同时仍提供 AI 能力。** ***\*RTX 4090D：\**相比标准 RTX 4090 规格降低的游戏显卡。 注意：这些型号的性能和规格可能与未受限版本有所不同。****
****随着中美关系的恶化，这个禁令清单将会继续不断更新****
**

------

### ** **

### **2、NVIDIA GPU 性能分析：为大模型选择合适的 GPU**

### **A、需要考虑的关键性能指标**

- ### ***\*显存容量：\**可用的显存数量。更大的模型需要更多显存来存储所有参数。例如，运行 7B 参数的模型可能需要至少 16GB 显存，而 70B 模型需要 40GB+ 显存。**

- ### ***\*计算能力：\**以 FLOPS（每秒浮点运算次数）衡量。更高的计算能力意味着更快的训练和推理速度。H100 的张量核心提供的计算能力显著高于消费级 GPU。**

- ### ***\*内存带宽：\**数据在显存中移动的速度。更高的带宽在处理大模型时减少瓶颈。H100 的 HBM3 显存提供比消费级显卡的 GDDR6X 更高的带宽。**

- ### ***\*功耗：\**更高性能的 GPU 消耗更多电力，需要更好的散热。数据中心需要考虑能效。RTX 4090 最高功耗 450W，而 H100 满载时可达 700W。**

### ** **

### ** **

### **B、LLM 任务性能对比**

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/pF9RLdqXYJWZRFTLWdyIh6oGVueJ4x6mJLQcFsK2zleJF5TRa7eyzZcVdYmRn2B1T8cDZkw52icd31ELPS9rllw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

**选择GPU可类比为选车：**训练大模型如同F1赛车，需高性能且昂贵的H100或多块A100；部署生产级大语言模型类似豪华跑车，需平衡性能与稳定性的A100、L40S或RTX A6000；而本地推理和测试则像家用轿车，经济实惠的RTX 4090等消费级显卡即可满足日常需求和小模型运行。不同场景对应不同层级的硬件投入，兼顾效率与成本效益。



------





## **4、一些有趣的问题**

![图片](./%E4%BA%8C%E3%80%81%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%AE%97%E5%8A%9B%E7%9B%B8%E5%85%B3%E7%9A%84%E9%82%A3%E4%BA%9B%E6%95%85%E4%BA%8B.assets/640-20250506175208618)

##  

### **Q: 为什么数据中心 GPU 比消费级 GPU 贵这么多？**

A: 数据中心 GPU 价格更高是因为：更大的显存容量、更高的计算能力、更好的可靠性和稳定性、专业的技术支持。



### **Q: 数据中心 GPU 需要特殊的散热和供电要求吗？**

A: 是的，数据中心 GPU 有特殊要求：需要专业的散热系统、可能需要特殊的电源供应、建议在数据中心环境中使用、需要定期维护和监控。



### **Q: 如何优化 GPU 性能？**

A: 可以通过以下方式优化性能：使用 CUDA 优化代码、采用混合精度训练、优化内存使用、使用 TensorRT 进行推理优化等。



------

### **  \**四、未来趋势与发展方向\****

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/pF9RLdqXYJWZRFTLWdyIh6oGVueJ4x6mGyvUpeF6D2lv7LsYoDdr64C1Ywicnhl6YicXCgEGWrUJcPqH5nZOMGaQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

- **构算力融合发展传统**

CPU、GPU与新型AI芯片（NPU、TPU等）协同工作的异构计算架构将成为主流。未来算力将不再局限于单一类型，而是根据任务特性动态调度最适合的计算单元。如华为昇腾计算架构实现了CPU、GPU、NPU的协同计算，显著提升了复杂场景下的计算效率。



- **绿色低碳算力崛起**

随着算力规模扩大，能源消耗与环境影响日益凸显。未来算力将向低能耗、高效能方向发展，液冷技术、碳排放管理将成为算力基础设施的标配。如亚马逊AWS承诺到2025年实现100%使用可再生能源，腾讯T-Block模块化数据中心PUE低至1.06。



- **算力服务化深入发展**

算力将越来越多地通过服务化方式提供，从IaaS向AIaaS转变。按需使用、弹性扩展、即用即付的算力服务模式将进一步普及。如阿里云推出的"智能算力网络"，允许企业根据实际需求动态调度不同地区的算力资源。



- **算力网络全面互联**

单中心算力向分布式算力网络转变，东数西算等国家战略加速算力资源在更大范围内的流动与共享。算力调度将突破组织与地域限制。如中国建设的"全国一体化大数据中心协同创新体系"，推动算力资源跨区域协同与优化配置。



- **专用算力加速崛起**

针对特定应用场景定制的专用算力将大量涌现，如视频编解码、自然语言处理、图像识别等领域的专用加速器将进一步提升特定任务的性能与效率。如谷歌为YouTube专门开发的视频转码加速器VCU，性能比传统方案提升20-33倍。



- **端侧算力崭露头角**

随着边缘计算与端侧AI的发展，智能手机、IoT设备等终端的算力将大幅提升，越来越多的AI推理将在端侧完成，减轻云端压力并提升隐私保护水平。如苹果M系列芯片集成了专用神经网络引擎，高通骁龙处理器整合NPU提升AI处理能力。



------